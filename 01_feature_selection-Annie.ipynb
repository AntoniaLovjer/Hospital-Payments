{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEAMMATES: Akshat and Annie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall goal is to predict whether a payment by a company to a medical doctor or facility\n",
    "was made as part of a research project or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading and manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "# from dirty_cat import TargetEncoder\n",
    "from category_encoders import TargetEncoder\n",
    "\n",
    "# scikit learn\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error, confusion_matrix, roc_auc_score, auc, average_precision_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# unbalanced sets\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The positive class corresponds to the payments that were made by a company to a doctor or facility that is part of the **research project**. The negative class on the other hand are the **general payments**. \n",
    "\n",
    "In the original data sets, the ratio of the positive class to the negative class is 1/20, making the positive class the minority class. \n",
    "\n",
    "Because the data sets are so large, we will subsample from the classes in order to maintain the same ratio. Thus we take 120K data points from Class 0, and 20K data points from Class 1. \n",
    "\n",
    "120K from the positive class turns out to be ~20% of the data, and 2M from the negative class is ~20% from the negative class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import 20% data randomly\n",
    "# p = 0.2\n",
    "# df0 = pd.read_csv('../payments2017/d0.csv', skiprows=lambda i: i>0 and random.random() > p)\n",
    "# df1 = pd.read_csv('../payments2017/d1.csv', skiprows=lambda i: i>0 and random.random() > p)\n",
    "\n",
    "# # Write sampled data for future use\n",
    "# df0.to_csv('../payments2017/gen_payments_sampled.csv')\n",
    "# df1.to_csv('../payments2017/res_payments_sampled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import from sampled files\n",
    "df0 = pd.read_csv('../payments2017/gen_payments_sampled.csv')\n",
    "df1 = pd.read_csv('../payments2017/res_payments_sampled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2135022, 76)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120693, 177)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Intersection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What features should be excluded because they leak the target information?\n",
    "\n",
    "There are 75 features present in the negative class, and 176 in the positive class. Our approach to combining the data sets for both the positive and the negative classs it to take an intersection of the features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 64 features present in the intersection of the two dataframes.\n"
     ]
    }
   ],
   "source": [
    "notPrs = list(set(list(df1.columns)).difference(list(df0.columns)))\n",
    "featureIntersection = list(set(list(df1.columns)).difference(notPrs))\n",
    "print(\"There are {} features present in the intersection of the two dataframes.\".format(len(featureIntersection) - 1))\n",
    "\n",
    "df1 = df1[featureIntersection]\n",
    "df0 = df0[featureIntersection]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we concatenate the two data sets, we add an indicator variable to each one specifying which class the data belongs to. We call this feature **target**, which is equal to 1 for the positive class and 0 for the negative class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2255715, 66)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Target'] = 1\n",
    "df0['Target'] = 0\n",
    "\n",
    "df = pd.concat([df1, df0], axis=0)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NA Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We examine the missing values of the data and see that a lot of the features have the majority of their data missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAs = df.isna().mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Recipient_Province                                                  0.999946\n",
       "Recipient_Postal_Code                                               0.999930\n",
       "Physician_License_State_code5                                       0.999841\n",
       "Physician_License_State_code4                                       0.999206\n",
       "Associated_Drug_or_Biological_NDC_5                                 0.997693\n",
       "Physician_License_State_code3                                       0.995460\n",
       "Product_Category_or_Therapeutic_Area_5                              0.993670\n",
       "Indicate_Drug_or_Biological_or_Device_or_Medical_Supply_5           0.993548\n",
       "Name_of_Drug_or_Biological_or_Device_or_Medical_Supply_5            0.993480\n",
       "Covered_or_Noncovered_Indicator_5                                   0.993370\n",
       "Teaching_Hospital_CCN                                               0.987726\n",
       "Teaching_Hospital_Name                                              0.987726\n",
       "Teaching_Hospital_ID                                                0.987726\n",
       "Associated_Drug_or_Biological_NDC_4                                 0.983701\n",
       "Physician_License_State_code2                                       0.980473\n",
       "Product_Category_or_Therapeutic_Area_4                              0.977446\n",
       "Indicate_Drug_or_Biological_or_Device_or_Medical_Supply_4           0.977287\n",
       "Name_of_Drug_or_Biological_or_Device_or_Medical_Supply_4            0.977133\n",
       "Covered_or_Noncovered_Indicator_4                                   0.976923\n",
       "Physician_Name_Suffix                                               0.975874\n",
       "Associated_Drug_or_Biological_NDC_3                                 0.934580\n",
       "Product_Category_or_Therapeutic_Area_3                              0.921326\n",
       "Indicate_Drug_or_Biological_or_Device_or_Medical_Supply_3           0.921075\n",
       "Name_of_Drug_or_Biological_or_Device_or_Medical_Supply_3            0.920936\n",
       "Covered_or_Noncovered_Indicator_3                                   0.919170\n",
       "Associated_Drug_or_Biological_NDC_2                                 0.827312\n",
       "Product_Category_or_Therapeutic_Area_2                              0.801839\n",
       "Indicate_Drug_or_Biological_or_Device_or_Medical_Supply_2           0.801538\n",
       "Name_of_Drug_or_Biological_or_Device_or_Medical_Supply_2            0.801461\n",
       "Covered_or_Noncovered_Indicator_2                                   0.796991\n",
       "                                                                      ...   \n",
       "Physician_Specialty                                                 0.056189\n",
       "Physician_Last_Name                                                 0.055018\n",
       "Physician_First_Name                                                0.055007\n",
       "Physician_License_State_code1                                       0.055002\n",
       "Physician_Primary_Type                                              0.054997\n",
       "Physician_Profile_ID                                                0.054997\n",
       "Covered_or_Noncovered_Indicator_1                                   0.054648\n",
       "Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_State      0.014252\n",
       "Recipient_State                                                     0.000124\n",
       "Recipient_Zip_Code                                                  0.000124\n",
       "Recipient_Primary_Business_Street_Address_Line1                     0.000054\n",
       "Recipient_City                                                      0.000054\n",
       "Recipient_Country                                                   0.000054\n",
       "Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Country    0.000000\n",
       "Submitting_Applicable_Manufacturer_or_Applicable_GPO_Name           0.000000\n",
       "Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Name       0.000000\n",
       "Date_of_Payment                                                     0.000000\n",
       "Form_of_Payment_or_Transfer_of_Value                                0.000000\n",
       "Dispute_Status_for_Publication                                      0.000000\n",
       "Payment_Publication_Date                                            0.000000\n",
       "Delay_in_Publication_Indicator                                      0.000000\n",
       "Program_Year                                                        0.000000\n",
       "Record_ID                                                           0.000000\n",
       "Covered_Recipient_Type                                              0.000000\n",
       "Total_Amount_of_Payment_USDollars                                   0.000000\n",
       "Change_Type                                                         0.000000\n",
       "Related_Product_Indicator                                           0.000000\n",
       "Unnamed: 0                                                          0.000000\n",
       "Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_ID         0.000000\n",
       "Target                                                              0.000000\n",
       "Length: 66, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NAs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop(columns='Target')\n",
    "target = df['Target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, random_state=42)\n",
    "model_scores = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_rus, y_train_rus = rus.fit_resample(X_train, y_train)\n",
    "X_train_rus = pd.DataFrame(X_train_rus, columns = X_train.columns)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_rus, y_train_rus, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Identification ~ Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We identifying possible irrelevant columns by looking at the features are Names or IDs, such as the hospial ID, record ID, postal codes or physcian names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['Recipient_Province', \n",
    "'Recipient_Postal_Code', \n",
    "'Recipient_Primary_Business_Street_Address_Line2',\n",
    "'Teaching_Hospital_Name', \n",
    "'Teaching_Hospital_CCN',\n",
    "'Teaching_Hospital_ID',\n",
    "'Physician_Name_Suffix',       \n",
    "'Program_Year', \n",
    "'Physician_Profile_ID', \n",
    "'Physician_Last_Name', \n",
    "'Physician_First_Name',\n",
    "'Record_ID',\n",
    "'Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_ID',\n",
    "'Physician_Profile_ID',\n",
    "'Recipient_Zip_Code',\n",
    "'Date_of_Payment',\n",
    "'Physician_Middle_Name',\n",
    "'Payment_Publication_Date', \n",
    "'Unnamed: 0' # Index col from one of the DFs\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As part of out baseline estimate, we will aslo drop columns with any missing value at all. Later on we will not drop all of them and try to impute the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nan_columns = NAs[NAs > 0] \n",
    "nan_columns = np.array(nan_columns.index)\n",
    "to_drop_baseline = list(set(nan_columns) | set(columns_to_drop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_Baseline = X_train.drop(columns=to_drop_baseline, axis ='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking single variable performances to identify leakage issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Covered_Recipient_Type': 0.9776754060061915,\n",
       " 'Submitting_Applicable_Manufacturer_or_Applicable_GPO_Name': 0.7644055216048586,\n",
       " 'Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Name': 0.8555550430863548,\n",
       " 'Form_of_Payment_or_Transfer_of_Value': 0.8169737585085819,\n",
       " 'Dispute_Status_for_Publication': 0.500808064079488,\n",
       " 'Delay_in_Publication_Indicator': 0.5006391044268736,\n",
       " 'Related_Product_Indicator': 0.541409525582002,\n",
       " 'Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Country': 0.549585674391527,\n",
       " 'Change_Type': 0.5181226628317186,\n",
       " 'Total_Amount_of_Payment_USDollars': 0.752034873891773}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objVars = ['Covered_Recipient_Type', # leaking target info\n",
    "            'Submitting_Applicable_Manufacturer_or_Applicable_GPO_Name', # leaking target info\n",
    "            'Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Name', # leaking target info\n",
    "           'Form_of_Payment_or_Transfer_of_Value',\n",
    "           'Dispute_Status_for_Publication', \n",
    "           'Delay_in_Publication_Indicator',\n",
    "           'Related_Product_Indicator',\n",
    "           'Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Country',\n",
    "           'Change_Type',\n",
    "           'Total_Amount_of_Payment_USDollars']\n",
    "\n",
    "single_var_auc = dict()\n",
    "single_var_acc = dict()\n",
    "\n",
    "for var in objVars:\n",
    "    \n",
    "    if var != 'Total_Amount_of_Payment_USDollars':\n",
    "        baseline_pipe = Pipeline([\n",
    "                                (\"dummies\", OneHotEncoder(handle_unknown='ignore')),\n",
    "                                (\"logreg\", LogisticRegression(solver='lbfgs'))])\n",
    "    else:\n",
    "        baseline_pipe = Pipeline([('scalar', StandardScaler()),\n",
    "                                   (\"logreg\", LogisticRegression(solver='lbfgs'))])\n",
    "\n",
    "    # Baseline Training and testing\n",
    "#     logreg = baseline_pipe.fit(X_train[[var]], y_train)\n",
    "#     y_score = logreg.predict_proba(X_val[[var]])\n",
    "    \n",
    "    # Store in dict\n",
    "#     single_var_auc[var] = roc_auc_score(y_val, y_score[:, 1])\n",
    "    \n",
    "    single_var_acc[var] = np.mean(cross_val_score(baseline_pipe, X_train[[var]], y_train, cv=5))\n",
    "    \n",
    "single_var_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Covered_Recipient_Type': 0.9776754060061915,\n",
       " 'Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Name': 0.8555550430863548,\n",
       " 'Form_of_Payment_or_Transfer_of_Value': 0.8169737585085819}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{key: single_var_acc[key] for key in single_var_acc if single_var_acc[key] > 0.8}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that three of the scores stand out: \n",
    "\n",
    "- Covered_Recipient_Type,\n",
    "- Form_of_Payment_or_Transfer_of_Value, and \n",
    "- Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Name\n",
    "\n",
    "It is likely that these features leak target information, and so we drop them from the sample. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dispute_Status_for_Publication                                          2\n",
       "Delay_in_Publication_Indicator                                          1\n",
       "Change_Type                                                             3\n",
       "Related_Product_Indicator                                               2\n",
       "Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Country       20\n",
       "Total_Amount_of_Payment_USDollars                                   35659\n",
       "Submitting_Applicable_Manufacturer_or_Applicable_GPO_Name             818\n",
       "dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_Baseline.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, we can remove the feature Delay_in_Publication_Indicator as it only has one unique value and would not add important information to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop += ['Covered_Recipient_Type', # leaking target info\n",
    "                    'Form_of_Payment_or_Transfer_of_Value', # leaking target info\n",
    "                    'Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Name', # leaking target info\n",
    "                    'Delay_in_Publication_Indicator' # single unique value\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "to_drop_baseline = list(set(nan_columns) | set(columns_to_drop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_Baseline = X_train.drop(columns=to_drop_baseline, axis ='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our new baseline model consists of 7 featues, 6 of which are categorical and 1 that is continuous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(136128, 6)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_Baseline.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dispute_Status_for_Publication</th>\n",
       "      <th>Change_Type</th>\n",
       "      <th>Related_Product_Indicator</th>\n",
       "      <th>Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Country</th>\n",
       "      <th>Total_Amount_of_Payment_USDollars</th>\n",
       "      <th>Submitting_Applicable_Manufacturer_or_Applicable_GPO_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>118253</th>\n",
       "      <td>No</td>\n",
       "      <td>UNCHANGED</td>\n",
       "      <td>Yes</td>\n",
       "      <td>United States</td>\n",
       "      <td>10619.1</td>\n",
       "      <td>Takeda Pharmaceuticals U.S.A., Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179387</th>\n",
       "      <td>No</td>\n",
       "      <td>UNCHANGED</td>\n",
       "      <td>No</td>\n",
       "      <td>United States</td>\n",
       "      <td>15</td>\n",
       "      <td>Incyte Corporation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110251</th>\n",
       "      <td>No</td>\n",
       "      <td>UNCHANGED</td>\n",
       "      <td>Yes</td>\n",
       "      <td>United States</td>\n",
       "      <td>1011.15</td>\n",
       "      <td>Eisai Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92018</th>\n",
       "      <td>No</td>\n",
       "      <td>UNCHANGED</td>\n",
       "      <td>Yes</td>\n",
       "      <td>United States</td>\n",
       "      <td>522.48</td>\n",
       "      <td>Alcon Research Ltd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29002</th>\n",
       "      <td>No</td>\n",
       "      <td>UNCHANGED</td>\n",
       "      <td>Yes</td>\n",
       "      <td>United States</td>\n",
       "      <td>13.03</td>\n",
       "      <td>Sanofi and Genzyme US Companies</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Dispute_Status_for_Publication Change_Type Related_Product_Indicator  \\\n",
       "118253                             No   UNCHANGED                       Yes   \n",
       "179387                             No   UNCHANGED                        No   \n",
       "110251                             No   UNCHANGED                       Yes   \n",
       "92018                              No   UNCHANGED                       Yes   \n",
       "29002                              No   UNCHANGED                       Yes   \n",
       "\n",
       "       Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Country  \\\n",
       "118253                                      United States                 \n",
       "179387                                      United States                 \n",
       "110251                                      United States                 \n",
       "92018                                       United States                 \n",
       "29002                                       United States                 \n",
       "\n",
       "       Total_Amount_of_Payment_USDollars  \\\n",
       "118253                           10619.1   \n",
       "179387                                15   \n",
       "110251                           1011.15   \n",
       "92018                             522.48   \n",
       "29002                              13.03   \n",
       "\n",
       "       Submitting_Applicable_Manufacturer_or_Applicable_GPO_Name  \n",
       "118253                Takeda Pharmaceuticals U.S.A., Inc.         \n",
       "179387                                 Incyte Corporation         \n",
       "110251                                         Eisai Inc.         \n",
       "92018                                  Alcon Research Ltd         \n",
       "29002                     Sanofi and Genzyme US Companies         "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_Baseline.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselining ~ Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can handle the categorical variables in multiple ways. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Defining continuous and categorical variables\n",
    "objVars = ['Dispute_Status_for_Publication', 'Change_Type',\n",
    "       'Related_Product_Indicator',\n",
    "       'Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Country',\n",
    "       'Submitting_Applicable_Manufacturer_or_Applicable_GPO_Name']\n",
    "\n",
    "contVars = ['Total_Amount_of_Payment_USDollars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining ColumnTransformer\n",
    "preprocessor = ColumnTransformer(transformers=[(\"dummies\", OneHotEncoder(handle_unknown='ignore'), objVars)],\n",
    "                                 remainder='passthrough')\n",
    "\n",
    "# Create pipeplines\n",
    "baseline_pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                          (\"logreg\", LogisticRegression(C=1000000, solver='lbfgs', max_iter=1000))\n",
    "                         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline Training and testing\n",
    "# logreg = baseline_pipe.fit(pd.DataFrame(X_train_rus, columns = X_train.columns), y_train_rus)\n",
    "# y_score = logreg.predict_proba(pd.DataFrame(X_train_rus, columns = X_train.columns))\n",
    "# baseline= roc_auc_score(y_train_rus, y_score[:, 1])\n",
    "\n",
    "baseline_acc = cross_val_score(baseline_pipe, X_train_Baseline, y_train, cv=5)\n",
    "baseline_cv_score_acc = np.mean(baseline_acc)\n",
    "model_scores['baseline_cv_acc'] = baseline_cv_score_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_roc = cross_val_score(baseline_pipe, X_train_Baseline, y_train, scoring= 'roc_auc', cv=5)\n",
    "baseline_cv_score_roc = np.mean(baseline_roc)\n",
    "model_scores['baseline_cv_roc'] = baseline_cv_score_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'baseline_cv_acc': 0.8829996800013659, 'baseline_cv_roc': 0.9507626293414436}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering ~ Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Handling the NAs:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputing NA with 'Missing' values --> I would still drop variables that have really high number of NAs - because some of them leak target info, but they have so many missing values that they don't actually leak. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_columns = NAs[NAs > 0.5] \n",
    "nan_columns = np.array(nan_columns.index)\n",
    "columns_to_drop = list(set(nan_columns) | set(columns_to_drop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_engineered = X_train.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_vars = X_train_engineered.drop(columns=['Total_Amount_of_Payment_USDollars']).columns.values\n",
    "cont_vars = ['Total_Amount_of_Payment_USDollars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Physician_Primary_Type',\n",
       "       'Indicate_Drug_or_Biological_or_Device_or_Medical_Supply_1',\n",
       "       'Dispute_Status_for_Publication',\n",
       "       'Product_Category_or_Therapeutic_Area_1', 'Recipient_State',\n",
       "       'Change_Type', 'Related_Product_Indicator',\n",
       "       'Name_of_Drug_or_Biological_or_Device_or_Medical_Supply_1',\n",
       "       'Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_State',\n",
       "       'Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Country',\n",
       "       'Associated_Drug_or_Biological_NDC_1', 'Physician_License_State_code1',\n",
       "       'Recipient_Primary_Business_Street_Address_Line1', 'Recipient_City',\n",
       "       'Total_Amount_of_Payment_USDollars',\n",
       "       'Covered_or_Noncovered_Indicator_1', 'Recipient_Country',\n",
       "       'Physician_Specialty',\n",
       "       'Submitting_Applicable_Manufacturer_or_Applicable_GPO_Name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_engineered.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify high cardinality categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physician_License_State_code1 60\n",
      "Physician_License_State_code2 54\n",
      "Covered_or_Noncovered_Indicator_5 3\n",
      "Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_State 47\n",
      "Recipient_City 15144\n",
      "Product_Category_or_Therapeutic_Area_5 202\n",
      "Associated_Drug_or_Biological_NDC_2 537\n",
      "Form_of_Payment_or_Transfer_of_Value 6\n",
      "Recipient_State 60\n",
      "Covered_or_Noncovered_Indicator_4 3\n",
      "Covered_or_Noncovered_Indicator_1 3\n",
      "Recipient_Primary_Business_Street_Address_Line1 299591\n",
      "Covered_or_Noncovered_Indicator_3 3\n",
      "Recipient_Country 15\n",
      "Physician_Primary_Type 7\n",
      "Physician_License_State_code5 32\n",
      "Indicate_Drug_or_Biological_or_Device_or_Medical_Supply_1 5\n",
      "Name_of_Drug_or_Biological_or_Device_or_Medical_Supply_5 526\n",
      "Physician_License_State_code4 43\n",
      "Physician_Specialty 374\n",
      "Change_Type 3\n",
      "Indicate_Drug_or_Biological_or_Device_or_Medical_Supply_5 5\n",
      "Name_of_Drug_or_Biological_or_Device_or_Medical_Supply_1 8260\n",
      "Name_of_Drug_or_Biological_or_Device_or_Medical_Supply_4 988\n",
      "Name_of_Drug_or_Biological_or_Device_or_Medical_Supply_2 2550\n",
      "Name_of_Drug_or_Biological_or_Device_or_Medical_Supply_3 1785\n",
      "Associated_Drug_or_Biological_NDC_4 189\n",
      "Associated_Drug_or_Biological_NDC_5 82\n",
      "Product_Category_or_Therapeutic_Area_1 1588\n",
      "Delay_in_Publication_Indicator 1\n",
      "Covered_or_Noncovered_Indicator_2 3\n",
      "Indicate_Drug_or_Biological_or_Device_or_Medical_Supply_2 5\n",
      "Dispute_Status_for_Publication 2\n",
      "Physician_License_State_code3 47\n",
      "Associated_Drug_or_Biological_NDC_3 360\n",
      "Related_Product_Indicator 2\n",
      "Indicate_Drug_or_Biological_or_Device_or_Medical_Supply_4 5\n",
      "Indicate_Drug_or_Biological_or_Device_or_Medical_Supply_3 5\n",
      "Product_Category_or_Therapeutic_Area_4 293\n",
      "Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Country 36\n",
      "Product_Category_or_Therapeutic_Area_3 391\n",
      "Associated_Drug_or_Biological_NDC_1 1221\n",
      "Product_Category_or_Therapeutic_Area_2 521\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify which variables to target encode\n",
    "target_based_encoding = []\n",
    "for col in obj_vars:\n",
    "    print(col, len(X_train_engineered[col].unique()))\n",
    "    \n",
    "    if len(X_train_engineered[col].unique()) > 100:\n",
    "        target_based_encoding.append(col)\n",
    "\n",
    "len(target_based_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final categorical variables\n",
    "categorical = [cols for cols in obj_vars if cols not in target_based_encoding]\n",
    "len(categorical) + len(target_based_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train-Test split\n",
    "# target = X_train_engineered['Target']\n",
    "# features = X_train_engineered.drop(columns='Target')\n",
    "# X_train, X_test, y_train, y_test = train_test_split(features, target, random_state=42)\n",
    "\n",
    "# Random undersampling\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_rus, y_train_rus = rus.fit_resample(X_train_engineered, y_train)\n",
    "X_train_rus = pd.DataFrame(X_train_rus, columns = X_train_engineered.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for target leakage again since we've added features not used before (for all variables except target encoded ones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute the missing values of the categorical data with the value \"Missing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Form_of_Payment_or_Transfer_of_Value': 0.8162809022541647,\n",
       " 'Submitting_Applicable_Manufacturer_or_Applicable_GPO_Name': 0.8614237063860364,\n",
       " 'Covered_Recipient_Type': 0.9791609259787764,\n",
       " 'Change_Type': 0.5311575726709323,\n",
       " 'Delay_in_Publication_Indicator': 0.5,\n",
       " 'Dispute_Status_for_Publication': 0.5000940359106548,\n",
       " 'Related_Product_Indicator': 0.5408447743691297,\n",
       " 'Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Name': 0.9425137176068114,\n",
       " 'Total_Amount_of_Payment_USDollars': 0.8966281827879227,\n",
       " 'Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Country': 0.5521105709016974}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_var = dict()\n",
    "\n",
    "cat_pipe = Pipeline([\n",
    "                        ('Impute', SimpleImputer(strategy='constant', fill_value=\"Missing\")),\n",
    "                        (\"dummies\", OneHotEncoder(handle_unknown='ignore')),\n",
    "                        (\"logreg\", LogisticRegression(C=1000000, solver='lbfgs', max_iter=1000))])\n",
    "\n",
    "cont_pipe = Pipeline([\n",
    "                        ('scalar', StandardScaler()),\n",
    "                        (\"logreg\", LogisticRegression(C=1000000, solver='lbfgs', max_iter=1000))])\n",
    "\n",
    "for var in X_train_rus.columns:\n",
    "    \n",
    "    if var != 'Total_Amount_of_Payment_USDollars':\n",
    "        # Baseline Training and testing\n",
    "        logreg = cat_pipe.fit(X_train_rus[[var]], y_train_rus)\n",
    "        y_score = logreg.predict_proba(X_train_rus[[var]])\n",
    "            \n",
    "    else:\n",
    "        # Baseline Training and testing\n",
    "        logreg = cont_pipe.fit(X_train_rus[[var]], y_train_rus)\n",
    "        y_score = logreg.predict_proba(X_train_rus[[var]])\n",
    "    \n",
    "    # Store in dict\n",
    "    single_var[var] = roc_auc_score(y_train_rus, y_score[:, 1])\n",
    "    \n",
    "single_var    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding leakage variables to list of variables to be removed. The threshold for deciding if the feature leaks target information is set to an AUC_ROC of 0.7. Similarly, we remove all the other associated features (1-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Form_of_Payment_or_Transfer_of_Value': 0.8162809022541647,\n",
       " 'Submitting_Applicable_Manufacturer_or_Applicable_GPO_Name': 0.8614237063860364,\n",
       " 'Covered_Recipient_Type': 0.9791609259787764,\n",
       " 'Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Name': 0.9425137176068114,\n",
       " 'Total_Amount_of_Payment_USDollars': 0.8966281827879227}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{key: single_var[key] for key in single_var if single_var[key] > 0.7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop += ['Name_of_Drug_or_Biological_or_Device_or_Medical_Supply_1', \n",
    "                    'Name_of_Drug_or_Biological_or_Device_or_Medical_Supply_2', \n",
    "                    'Name_of_Drug_or_Biological_or_Device_or_Medical_Supply_3',\n",
    "                    'Name_of_Drug_or_Biological_or_Device_or_Medical_Supply_4',\n",
    "                    'Name_of_Drug_or_Biological_or_Device_or_Medical_Supply_5',\n",
    "                    \n",
    "                    'Physician_License_State_code1',\n",
    "                    'Physician_License_State_code2',\n",
    "                    'Physician_License_State_code3',\n",
    "                    'Physician_License_State_code4',\n",
    "                    'Physician_License_State_code5', \n",
    "                    \n",
    "                    'Recipient_Primary_Business_Street_Address_Line1',\n",
    "                    'Recipient_Primary_Business_Street_Address_Line2',\n",
    "                    'Recipient_Primary_Business_Street_Address_Line3',\n",
    "                    'Recipient_Primary_Business_Street_Address_Line4',\n",
    "                    'Recipient_Primary_Business_Street_Address_Line5',\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                   'Physician_Primary_Type',\n",
    "                   'Physician_Specialty',\n",
    "                   'Physician_License_State_code1', \n",
    "                   #Associated_Drug_or_Biological_NDC_1, \n",
    "                   #Form_of_Payment_or_Transfer_of_Value, \n",
    "                   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_engineered = X_train.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_vars = X_train_engineered.drop(columns=['Total_Amount_of_Payment_USDollars']).columns.values\n",
    "cont_vars = ['Total_Amount_of_Payment_USDollars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physician_License_State_code2 54\n",
      "Covered_or_Noncovered_Indicator_5 3\n",
      "Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_State 47\n",
      "Recipient_City 15144\n",
      "Product_Category_or_Therapeutic_Area_5 202\n",
      "Associated_Drug_or_Biological_NDC_2 537\n",
      "Form_of_Payment_or_Transfer_of_Value 6\n",
      "Recipient_State 60\n",
      "Covered_or_Noncovered_Indicator_4 3\n",
      "Covered_or_Noncovered_Indicator_1 3\n",
      "Covered_or_Noncovered_Indicator_3 3\n",
      "Recipient_Country 15\n",
      "Physician_License_State_code5 32\n",
      "Indicate_Drug_or_Biological_or_Device_or_Medical_Supply_1 5\n",
      "Name_of_Drug_or_Biological_or_Device_or_Medical_Supply_5 526\n",
      "Physician_License_State_code4 43\n",
      "Change_Type 3\n",
      "Indicate_Drug_or_Biological_or_Device_or_Medical_Supply_5 5\n",
      "Name_of_Drug_or_Biological_or_Device_or_Medical_Supply_4 988\n",
      "Name_of_Drug_or_Biological_or_Device_or_Medical_Supply_2 2550\n",
      "Name_of_Drug_or_Biological_or_Device_or_Medical_Supply_3 1785\n",
      "Associated_Drug_or_Biological_NDC_4 189\n",
      "Associated_Drug_or_Biological_NDC_5 82\n",
      "Product_Category_or_Therapeutic_Area_1 1588\n",
      "Delay_in_Publication_Indicator 1\n",
      "Covered_or_Noncovered_Indicator_2 3\n",
      "Indicate_Drug_or_Biological_or_Device_or_Medical_Supply_2 5\n",
      "Dispute_Status_for_Publication 2\n",
      "Physician_License_State_code3 47\n",
      "Associated_Drug_or_Biological_NDC_3 360\n",
      "Related_Product_Indicator 2\n",
      "Indicate_Drug_or_Biological_or_Device_or_Medical_Supply_4 5\n",
      "Indicate_Drug_or_Biological_or_Device_or_Medical_Supply_3 5\n",
      "Product_Category_or_Therapeutic_Area_4 293\n",
      "Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Country 36\n",
      "Product_Category_or_Therapeutic_Area_3 391\n",
      "Associated_Drug_or_Biological_NDC_1 1221\n",
      "Product_Category_or_Therapeutic_Area_2 521\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify which variables to target encode\n",
    "target_based_encoding = []\n",
    "for col in obj_vars:\n",
    "    print(col, len(X_train_engineered[col].unique()))\n",
    "    \n",
    "    if len(X_train_engineered[col].unique()) > 100:\n",
    "        target_based_encoding.append(col)\n",
    "\n",
    "len(target_based_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final categorical variables\n",
    "categorical = [cols for cols in obj_vars if cols not in target_based_encoding]\n",
    "len(categorical) + len(target_based_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random undersampling\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_rus, y_train_rus = rus.fit_resample(X_train_engineered, y_train)\n",
    "X_train_rus = pd.DataFrame(X_train_rus, columns = X_train_engineered.columns)\n",
    "X_train_rus = X_train_rus[categorical + cont_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Physician_License_State_code2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Covered_or_Noncovered_Indicator_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Applicable_Manufacturer_or_Applicable_GPO_Maki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recipient_State</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Associated_Drug_or_Biological_NDC_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Applicable_Manufacturer_or_Applicable_GPO_Maki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Covered_or_Noncovered_Indicator_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dispute_Status_for_Publication</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Physician_License_State_code3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Form_of_Payment_or_Transfer_of_Value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Related_Product_Indicator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Indicate_Drug_or_Biological_or_Device_or_Medic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Change_Type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Delay_in_Publication_Indicator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Indicate_Drug_or_Biological_or_Device_or_Medic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Recipient_Country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Covered_or_Noncovered_Indicator_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Physician_License_State_code5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Indicate_Drug_or_Biological_or_Device_or_Medic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Physician_License_State_code4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Indicate_Drug_or_Biological_or_Device_or_Medic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Covered_or_Noncovered_Indicator_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Covered_or_Noncovered_Indicator_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Indicate_Drug_or_Biological_or_Device_or_Medic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Total_Amount_of_Payment_USDollars</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    0\n",
       "0                       Physician_License_State_code2\n",
       "1                   Covered_or_Noncovered_Indicator_3\n",
       "2   Applicable_Manufacturer_or_Applicable_GPO_Maki...\n",
       "3                                     Recipient_State\n",
       "4                 Associated_Drug_or_Biological_NDC_5\n",
       "5   Applicable_Manufacturer_or_Applicable_GPO_Maki...\n",
       "6                   Covered_or_Noncovered_Indicator_5\n",
       "7                      Dispute_Status_for_Publication\n",
       "8                       Physician_License_State_code3\n",
       "9                Form_of_Payment_or_Transfer_of_Value\n",
       "10                          Related_Product_Indicator\n",
       "11  Indicate_Drug_or_Biological_or_Device_or_Medic...\n",
       "12                                        Change_Type\n",
       "13                     Delay_in_Publication_Indicator\n",
       "14  Indicate_Drug_or_Biological_or_Device_or_Medic...\n",
       "15                                  Recipient_Country\n",
       "16                  Covered_or_Noncovered_Indicator_4\n",
       "17                      Physician_License_State_code5\n",
       "18  Indicate_Drug_or_Biological_or_Device_or_Medic...\n",
       "19                      Physician_License_State_code4\n",
       "20  Indicate_Drug_or_Biological_or_Device_or_Medic...\n",
       "21                  Covered_or_Noncovered_Indicator_1\n",
       "22                  Covered_or_Noncovered_Indicator_2\n",
       "23  Indicate_Drug_or_Biological_or_Device_or_Medic...\n",
       "24                  Total_Amount_of_Payment_USDollars"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train_rus.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model without high cardinality categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model without high cardinality categorical variables\n",
    "# Defining ColumnTransformer\n",
    "preprocessor = ColumnTransformer(transformers=[(\"scalar\", StandardScaler(), cont_vars),\n",
    "                                              (\"dummies\", make_pipeline(SimpleImputer(strategy='constant', fill_value=\"Missing\"),\n",
    "                                                                        OneHotEncoder(handle_unknown='ignore')), categorical)\n",
    "                                             ])\n",
    "\n",
    "# Create pipeplines\n",
    "take2_pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                             (\"logreg\", LogisticRegression(C=1000000, solver='lbfgs', max_iter=500))\n",
    "                            ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Baseline Training and testing\n",
    "imputed_model = cross_val_score(take2_pipe, X_train_rus, y_train_rus, scoring='roc_auc', cv=5)\n",
    "imputed_model_cv_score = np.mean(imputed_model)\n",
    "model_scores['imputed_model_cv_score'] = imputed_model_cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'baseline_cv': 0.9362845959438688,\n",
       " 'imputed_model_cv_score': 0.9535514508509628}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Including Categorical Columns with high cardinality with Target Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding separately as takes a lot of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random undersampling\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_rus, y_train_rus = rus.fit_resample(X_train_engineered, y_train)\n",
    "X_train_rus = pd.DataFrame(X_train_rus, columns = X_train_engineered.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target Encoding\n",
    "# # Takes hell lot of time (~10mins)\n",
    "# # but does the job\n",
    "\n",
    "# Convert NAs of categorical variables to None\n",
    "for col in target_based_encoding:\n",
    "    X_train_rus[col].fillna(\"None\", inplace=True)\n",
    "\n",
    "# Fitting target encoder\n",
    "target_enc = TargetEncoder(verbose=1, cols=target_based_encoding, return_df=True, handle_unknown='ignore')\n",
    "targets_encoded = target_enc.fit_transform(X_train_rus, y_train_rus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining ColumnTransformer\n",
    "preprocessor = ColumnTransformer(transformers=[(\"scalar\", StandardScaler(), cont_vars),\n",
    "                                              (\"dummies\", make_pipeline(SimpleImputer(strategy='constant', fill_value=\"Missing\"),\n",
    "                                                                        OneHotEncoder(handle_unknown='ignore')), categorical)\n",
    "                                             ], remainder='passthrough')\n",
    "\n",
    "# Create pipeplines\n",
    "take3_pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                             (\"logreg\", LogisticRegression(C=1000000, solver='lbfgs', max_iter=500))\n",
    "                            ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Baseline Training and testing\n",
    "target_enc_model = cross_val_score(take3_pipe, targets_encoded, y_train_rus, scoring='roc_auc', cv=5)\n",
    "target_enc_model_cv_score = np.mean(target_enc_model)\n",
    "model_scores['target_enc_model'] = target_enc_model_cv_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target_enc_model': 0.981209215106308}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining ColumnTransformer\n",
    "preprocessor = ColumnTransformer(transformers=[(\"scalar\", StandardScaler(), cont_vars),\n",
    "                                              (\"dummies\", make_pipeline(SimpleImputer(strategy='constant', fill_value=\"Missing\"),\n",
    "                                                                        OneHotEncoder(handle_unknown='ignore')), categorical)\n",
    "                                             ], remainder='passthrough')\n",
    "\n",
    "# Create pipeplines\n",
    "svc_pipe = Pipeline(steps=[(\"preprocessor\", preprocessor),\n",
    "                           (\"SVC\", LinearSVC()) \n",
    "                          ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Baseline training and testing\n",
    "svc_model = cross_val_score(svc_pipe, targets_encoded, y_train_rus, scoring='roc_auc', cv=5)\n",
    "svc_model_cv_score = np.mean(svc_model)\n",
    "model_scores['svc_model'] = svc_model_cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'baseline_cv': 0.9362845959438688,\n",
       " 'imputed_model_cv_score': 0.9535514508509628,\n",
       " 'target_enc_model': 0.9829174974299428,\n",
       " 'svc_model': 0.9811154450064498}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining ColumnTransformer\n",
    "rf_preprocessor = ColumnTransformer(transformers=[\n",
    "                                                (\"dummies\", make_pipeline(SimpleImputer(strategy='constant', fill_value=\"Missing\"),\n",
    "                                                                        OneHotEncoder(handle_unknown='ignore')), categorical)\n",
    "                                             ], remainder='passthrough')\n",
    "\n",
    "# Create pipeplines\n",
    "rf_pipe = Pipeline(steps=[(\"preprocessor\", preprocessor),\n",
    "                           (\"randomForest\", RandomForestClassifier()) \n",
    "                          ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9932242352899097"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training and testing\n",
    "rf_model = cross_val_score(rf_pipe, targets_encoded, y_train_rus, scoring='roc_auc', cv=5)\n",
    "rf_model_cv_score = np.mean(rf_model)\n",
    "rf_model_cv_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance ~ Task 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for drawing ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score = logreg.fit(pd.DataFrame(X_train_rus, columns = X_train.columns), \n",
    "                     pd.DataFrame(y_train_rus)).predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = logreg.predict(X_test)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_test, preds).ravel()\n",
    "print([tn, fp])\n",
    "print([fn, tp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "roc_auc_score(y_test, y_score[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_roc(y_test, list(y_score[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "average_precision_score(y_test, y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(y_test, y_score):\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_score)\n",
    "    \n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    lw = 2\n",
    "    plt.plot(fpr, tpr, color='darkorange',\n",
    "             lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = logreg.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aml",
   "language": "python",
   "name": "aml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
