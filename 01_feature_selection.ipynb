{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEAMMATES: Akshat and Annie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall goal is to predict whether a payment by a company to a medical doctor or facility\n",
    "was made as part of a research project or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading and manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from dirty_cat import TargetEncoder\n",
    "\n",
    "# scikit learn\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error, confusion_matrix, roc_auc_score, auc, average_precision_score\n",
    "\n",
    "# unbalanced sets\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The positive class corresponds to the payments that were made by a company to a doctor or facility that is part of the **research project**. The negative class on the other hand are the **general payments**. \n",
    "\n",
    "In the original data sets, the ratio of the positive class to the negative class is 1/20, making the positive class the minority class. \n",
    "\n",
    "Because the data sets are so large, we will subsample from the classes in order to maintain the same ratio. Thus we take 120K data points from Class 0, and 20K data points from Class 1. \n",
    "\n",
    "120K from the positive class turns out to be ~20% of the data, and 2M from the negative class is ~20% from the negative class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import 20% data randomly\n",
    "# p = 0.2\n",
    "# df0 = pd.read_csv('../payments2017/d0.csv', skiprows=lambda i: i>0 and random.random() > p)\n",
    "# df1 = pd.read_csv('../payments2017/d1.csv', skiprows=lambda i: i>0 and random.random() > p)\n",
    "\n",
    "# Write sampled data for future use\n",
    "# df0.to_csv('../payments2017/gen_payments_sampled.csv')\n",
    "# df1.to_csv('../payments2017/res_payments_sampled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3020: DtypeWarning: Columns (5,8,10,12,15,17,18,22,23,24,25,36,37,38,41,42,43,44,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3020: DtypeWarning: Columns (3,6,8,9,10,11,16,18,19,20,21,22,23,24,25,31,38,39,43,44,45,46,48,49,50,51,52,53,54,55,56,57,60,61,62,63,68,69,70,71,72,73,74,75,76,77,80,81,82,88,89,90,92,93,94,95,96,97,100,101,102,108,109,110,111,112,113,114,115,116,117,120,121,122,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,161,162,163,174,175,176) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Import from sampled files\n",
    "df0 = pd.read_csv('../payments2017/gen_payments_sampled.csv')\n",
    "df1 = pd.read_csv('../payments2017/res_payments_sampled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2132686, 76)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120511, 177)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Intersection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What features should be excluded because they leak the target information?\n",
    "\n",
    "There are 75 features present in the negative class, and 176 in the positive class. Our approach to combining the data sets for both the positive and the negative classs it to take an intersection of the features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 65 features present in the intersection of the two dataframes.\n"
     ]
    }
   ],
   "source": [
    "notPrs = list(set(list(df1.columns)).difference(list(df0.columns)))\n",
    "featureIntersection = list(set(list(df1.columns)).difference(notPrs))\n",
    "print(\"There are {} features present in the intersection of the two dataframes.\".format(len(featureIntersection) - 1))\n",
    "\n",
    "df1 = df1[featureIntersection]\n",
    "df0 = df0[featureIntersection]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we concatenate the two data sets, we add an indicator variable to each one specifying which class the data belongs to. We call this feature **target**, which is equal to 1 for the positive class and 0 for the negative class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2253197, 66)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Target'] = 1\n",
    "df0['Target'] = 0\n",
    "\n",
    "df = pd.concat([df1, df0], axis=0)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAs = df.isna().mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Recipient_Province                                                  0.999945\n",
       "Recipient_Postal_Code                                               0.999931\n",
       "Physician_License_State_code5                                       0.999826\n",
       "Physician_License_State_code4                                       0.999209\n",
       "Associated_Drug_or_Biological_NDC_5                                 0.997671\n",
       "Physician_License_State_code3                                       0.995469\n",
       "Product_Category_or_Therapeutic_Area_5                              0.993623\n",
       "Indicate_Drug_or_Biological_or_Device_or_Medical_Supply_5           0.993483\n",
       "Name_of_Drug_or_Biological_or_Device_or_Medical_Supply_5            0.993420\n",
       "Covered_or_Noncovered_Indicator_5                                   0.993296\n",
       "Teaching_Hospital_CCN                                               0.987752\n",
       "Teaching_Hospital_ID                                                0.987752\n",
       "Teaching_Hospital_Name                                              0.987752\n",
       "Associated_Drug_or_Biological_NDC_4                                 0.983768\n",
       "Physician_License_State_code2                                       0.980442\n",
       "Product_Category_or_Therapeutic_Area_4                              0.977459\n",
       "Indicate_Drug_or_Biological_or_Device_or_Medical_Supply_4           0.977279\n",
       "Name_of_Drug_or_Biological_or_Device_or_Medical_Supply_4            0.977121\n",
       "Covered_or_Noncovered_Indicator_4                                   0.976900\n",
       "Physician_Name_Suffix                                               0.975787\n",
       "Associated_Drug_or_Biological_NDC_3                                 0.934709\n",
       "Product_Category_or_Therapeutic_Area_3                              0.921423\n",
       "Indicate_Drug_or_Biological_or_Device_or_Medical_Supply_3           0.921151\n",
       "Name_of_Drug_or_Biological_or_Device_or_Medical_Supply_3            0.921004\n",
       "Covered_or_Noncovered_Indicator_3                                   0.919222\n",
       "Associated_Drug_or_Biological_NDC_2                                 0.827624\n",
       "Product_Category_or_Therapeutic_Area_2                              0.802161\n",
       "Indicate_Drug_or_Biological_or_Device_or_Medical_Supply_2           0.801846\n",
       "Name_of_Drug_or_Biological_or_Device_or_Medical_Supply_2            0.801756\n",
       "Covered_or_Noncovered_Indicator_2                                   0.797244\n",
       "                                                                      ...   \n",
       "Physician_Specialty                                                 0.056165\n",
       "Physician_Last_Name                                                 0.055002\n",
       "Physician_First_Name                                                0.054988\n",
       "Physician_License_State_code1                                       0.054983\n",
       "Physician_Profile_ID                                                0.054979\n",
       "Physician_Primary_Type                                              0.054979\n",
       "Covered_or_Noncovered_Indicator_1                                   0.054517\n",
       "Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_State      0.014239\n",
       "Recipient_Zip_Code                                                  0.000122\n",
       "Recipient_State                                                     0.000122\n",
       "Recipient_Primary_Business_Street_Address_Line1                     0.000054\n",
       "Recipient_City                                                      0.000053\n",
       "Recipient_Country                                                   0.000053\n",
       "Target                                                              0.000000\n",
       "Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_ID         0.000000\n",
       "Program_Year                                                        0.000000\n",
       "Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Name       0.000000\n",
       "Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Country    0.000000\n",
       "Total_Amount_of_Payment_USDollars                                   0.000000\n",
       "Form_of_Payment_or_Transfer_of_Value                                0.000000\n",
       "Change_Type                                                         0.000000\n",
       "Payment_Publication_Date                                            0.000000\n",
       "Covered_Recipient_Type                                              0.000000\n",
       "Related_Product_Indicator                                           0.000000\n",
       "Date_of_Payment                                                     0.000000\n",
       "Submitting_Applicable_Manufacturer_or_Applicable_GPO_Name           0.000000\n",
       "Record_ID                                                           0.000000\n",
       "Delay_in_Publication_Indicator                                      0.000000\n",
       "Dispute_Status_for_Publication                                      0.000000\n",
       "Unnamed: 0                                                          0.000000\n",
       "Length: 66, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NAs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Baseline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identifying possible irrelevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['Recipient_Province', \n",
    "'Recipient_Postal_Code', \n",
    "'Recipient_Primary_Business_Street_Address_Line2',\n",
    "'Teaching_Hospital_Name', \n",
    "'Teaching_Hospital_CCN',\n",
    "'Teaching_Hospital_ID',\n",
    "'Physician_Name_Suffix',       \n",
    "'Program_Year', \n",
    "'Physician_Profile_ID', \n",
    "'Physician_Last_Name', \n",
    "'Physician_First_Name',\n",
    "'Record_ID',\n",
    "'Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_ID',\n",
    "'Physician_Profile_ID',\n",
    "'Recipient_Zip_Code',\n",
    "'Date_of_Payment',\n",
    "'Physician_Middle_Name',\n",
    "# 'Covered_Recipient_Type', # leaking target info\n",
    "'Payment_Publication_Date', \n",
    "# 'Submitting_Applicable_Manufacturer_or_Applicable_GPO_Name', # leaking target info\n",
    "# 'Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Name', # leaking target info\n",
    "'Unnamed: 0' # Index col from one of the DFs\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping Columns with any missing value at all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nan_columns = NAs[NAs > 0] \n",
    "nan_columns = np.array(nan_columns.index)\n",
    "to_drop_baseline = list(set(nan_columns) | set(columns_to_drop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfBaseline = df.drop(columns=to_drop_baseline, axis ='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking single variable performances to identify leakage issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\pipeline.py:381: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Covered_Recipient_Type': 0.9792059412507333,\n",
       " 'Submitting_Applicable_Manufacturer_or_Applicable_GPO_Name': 0.8615011802682625,\n",
       " 'Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Name': 0.94239000863121,\n",
       " 'Form_of_Payment_or_Transfer_of_Value': 0.8164754233924769,\n",
       " 'Dispute_Status_for_Publication': 0.500204847692972,\n",
       " 'Delay_in_Publication_Indicator': 0.5,\n",
       " 'Related_Product_Indicator': 0.5419384128179292,\n",
       " 'Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Country': 0.5523350569889764,\n",
       " 'Change_Type': 0.5313082741537394,\n",
       " 'Total_Amount_of_Payment_USDollars': 0.8982626413550628}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objVars = ['Covered_Recipient_Type', # leaking target info\n",
    "            'Submitting_Applicable_Manufacturer_or_Applicable_GPO_Name', # leaking target info\n",
    "            'Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Name', # leaking target info\n",
    "           'Form_of_Payment_or_Transfer_of_Value',\n",
    "           'Dispute_Status_for_Publication', \n",
    "           'Delay_in_Publication_Indicator',\n",
    "           'Related_Product_Indicator',\n",
    "           'Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Country',\n",
    "           'Change_Type',\n",
    "           'Total_Amount_of_Payment_USDollars']\n",
    "\n",
    "target = dfBaseline['Target']\n",
    "\n",
    "single_var = dict()\n",
    "\n",
    "features = dfBaseline.drop(columns='Target')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target)\n",
    "\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_rus, y_train_rus = rus.fit_resample(X_train, y_train)    \n",
    "\n",
    "X_train_rus = pd.DataFrame(X_train_rus, columns=X_train.columns)\n",
    "X_test = pd.DataFrame(X_test, columns=X_train.columns)\n",
    "\n",
    "for var in objVars:\n",
    "    \n",
    "    if var != 'Total_Amount_of_Payment_USDollars':\n",
    "        baseline_pipe = Pipeline([\n",
    "                                (\"dummies\", OneHotEncoder(handle_unknown='ignore')),\n",
    "                                (\"logreg\", LogisticRegression(solver='lbfgs', max_iter=1000))])\n",
    "    else:\n",
    "        baseline_pipe = Pipeline([\n",
    "                                ('scalar', StandardScaler()),\n",
    "                                (\"logreg\", LogisticRegression(solver='lbfgs', max_iter=1000))])\n",
    "\n",
    "    # Baseline Training and testing\n",
    "    logreg = baseline_pipe.fit(X_train_rus[[var]], y_train_rus)\n",
    "    y_score = logreg.predict_proba(X_train_rus[[var]])\n",
    "    \n",
    "    # Store in dict\n",
    "    single_var[var] = roc_auc_score(y_train_rus, y_score[:, 1])\n",
    "    \n",
    "single_var    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modifying column to drop list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['Recipient_Province', \n",
    "'Recipient_Postal_Code', \n",
    "'Recipient_Primary_Business_Street_Address_Line2',\n",
    "'Teaching_Hospital_Name', \n",
    "'Teaching_Hospital_CCN',\n",
    "'Teaching_Hospital_ID',\n",
    "'Physician_Name_Suffix',       \n",
    "'Program_Year', \n",
    "'Physician_Profile_ID', \n",
    "'Physician_Last_Name', \n",
    "'Physician_First_Name',\n",
    "'Record_ID',\n",
    "'Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_ID',\n",
    "'Physician_Profile_ID',\n",
    "'Recipient_Zip_Code',\n",
    "'Date_of_Payment',\n",
    "'Physician_Middle_Name',\n",
    "'Covered_Recipient_Type', # leaking target info\n",
    "'Payment_Publication_Date', \n",
    "# 'Submitting_Applicable_Manufacturer_or_Applicable_GPO_Name', # leaking target info\n",
    "'Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Name', # leaking target info\n",
    "'Unnamed: 0' # Index col from one of the DFs\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nan_columns = NAs[NAs > 0] \n",
    "nan_columns = np.array(nan_columns.index)\n",
    "to_drop_baseline = list(set(nan_columns) | set(columns_to_drop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfBaseline = df.drop(columns=to_drop_baseline, axis ='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2253197, 9)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfBaseline.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Country</th>\n",
       "      <th>Form_of_Payment_or_Transfer_of_Value</th>\n",
       "      <th>Change_Type</th>\n",
       "      <th>Submitting_Applicable_Manufacturer_or_Applicable_GPO_Name</th>\n",
       "      <th>Delay_in_Publication_Indicator</th>\n",
       "      <th>Dispute_Status_for_Publication</th>\n",
       "      <th>Related_Product_Indicator</th>\n",
       "      <th>Total_Amount_of_Payment_USDollars</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United States</td>\n",
       "      <td>Cash or cash equivalent</td>\n",
       "      <td>UNCHANGED</td>\n",
       "      <td>Nielsen BioSciences, Inc.</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>8531.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United States</td>\n",
       "      <td>Cash or cash equivalent</td>\n",
       "      <td>UNCHANGED</td>\n",
       "      <td>Nielsen BioSciences, Inc.</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>76433.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>United States</td>\n",
       "      <td>Cash or cash equivalent</td>\n",
       "      <td>UNCHANGED</td>\n",
       "      <td>Nielsen BioSciences, Inc.</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>49312.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>United States</td>\n",
       "      <td>Cash or cash equivalent</td>\n",
       "      <td>UNCHANGED</td>\n",
       "      <td>Mission Pharmacal Company</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>546.15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>United States</td>\n",
       "      <td>Cash or cash equivalent</td>\n",
       "      <td>UNCHANGED</td>\n",
       "      <td>Mission Pharmacal Company</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>225.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Country  \\\n",
       "0                                      United States                 \n",
       "1                                      United States                 \n",
       "2                                      United States                 \n",
       "3                                      United States                 \n",
       "4                                      United States                 \n",
       "\n",
       "  Form_of_Payment_or_Transfer_of_Value Change_Type  \\\n",
       "0              Cash or cash equivalent   UNCHANGED   \n",
       "1              Cash or cash equivalent   UNCHANGED   \n",
       "2              Cash or cash equivalent   UNCHANGED   \n",
       "3              Cash or cash equivalent   UNCHANGED   \n",
       "4              Cash or cash equivalent   UNCHANGED   \n",
       "\n",
       "  Submitting_Applicable_Manufacturer_or_Applicable_GPO_Name  \\\n",
       "0                          Nielsen BioSciences, Inc.          \n",
       "1                          Nielsen BioSciences, Inc.          \n",
       "2                          Nielsen BioSciences, Inc.          \n",
       "3                          Mission Pharmacal Company          \n",
       "4                          Mission Pharmacal Company          \n",
       "\n",
       "  Delay_in_Publication_Indicator Dispute_Status_for_Publication  \\\n",
       "0                             No                             No   \n",
       "1                             No                             No   \n",
       "2                             No                             No   \n",
       "3                             No                             No   \n",
       "4                             No                             No   \n",
       "\n",
       "  Related_Product_Indicator  Total_Amount_of_Payment_USDollars  Target  \n",
       "0                       Yes                            8531.00       1  \n",
       "1                       Yes                           76433.50       1  \n",
       "2                       Yes                           49312.50       1  \n",
       "3                        No                             546.15       1  \n",
       "4                        No                             225.00       1  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfBaseline.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Columns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Applicable_Manufacturer_or_Applicable_GPO_Maki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Form_of_Payment_or_Transfer_of_Value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Change_Type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Submitting_Applicable_Manufacturer_or_Applicab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Delay_in_Publication_Indicator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dispute_Status_for_Publication</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Related_Product_Indicator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Total_Amount_of_Payment_USDollars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Target</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Columns\n",
       "0  Applicable_Manufacturer_or_Applicable_GPO_Maki...\n",
       "1               Form_of_Payment_or_Transfer_of_Value\n",
       "2                                        Change_Type\n",
       "3  Submitting_Applicable_Manufacturer_or_Applicab...\n",
       "4                     Delay_in_Publication_Indicator\n",
       "5                     Dispute_Status_for_Publication\n",
       "6                          Related_Product_Indicator\n",
       "7                  Total_Amount_of_Payment_USDollars\n",
       "8                                             Target"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dfBaseline.columns, columns=['Columns'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test split\n",
    "target = dfBaseline['Target']\n",
    "features = dfBaseline.drop(columns='Target')\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target)\n",
    "\n",
    "# Random undersampling\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_rus, y_train_rus = rus.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Baselining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without target encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Defining continuous and categorical variables\n",
    "objVars = ['Form_of_Payment_or_Transfer_of_Value',\n",
    "           'Dispute_Status_for_Publication', \n",
    "           'Delay_in_Publication_Indicator',\n",
    "           'Related_Product_Indicator',\n",
    "           'Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Country',\n",
    "           'Change_Type',\n",
    "           'Submitting_Applicable_Manufacturer_or_Applicable_GPO_Name']\n",
    "\n",
    "contVars = ['Total_Amount_of_Payment_USDollars']\n",
    "\n",
    "# contVars_ct = ColumnTransformer([(\"scalar\", StandardScaler(), contVars)])\n",
    "\n",
    "# catVars_ct = ColumnTransformer([(\"dummies\", OneHotEncoder(handle_unknown='ignore'), objVars)])\n",
    "\n",
    "# (\"target_encoder\", TargetEncoder(clf_type=\"binary_clf\"), target_based_encoding)\n",
    "\n",
    "# baseline_pipe = Pipeline([\n",
    "#                         (\"contvars\", contVars_ct),\n",
    "#                         (\"catvars\", catVars_ct),\n",
    "#                         (\"logreg\", LogisticRegression(solver='lbfgs', max_iter=1000))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining ColumnTransformer\n",
    "preprocessor = ColumnTransformer(transformers=[(\"scalar\", StandardScaler(), contVars),\n",
    "                                              (\"dummies\", OneHotEncoder(handle_unknown='ignore'), objVars)\n",
    "                                             ])\n",
    "\n",
    "# Create pipeplines\n",
    "baseline_pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                          (\"logreg\", LogisticRegression(solver='lbfgs', max_iter=1000))\n",
    "                         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\pipeline.py:605: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  res = transformer.transform(X)\n",
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\pipeline.py:605: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  res = transformer.transform(X)\n",
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\pipeline.py:605: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  res = transformer.transform(X)\n",
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\pipeline.py:605: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  res = transformer.transform(X)\n",
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\pipeline.py:605: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  res = transformer.transform(X)\n",
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\pipeline.py:605: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  res = transformer.transform(X)\n",
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\pipeline.py:605: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  res = transformer.transform(X)\n",
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\pipeline.py:605: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  res = transformer.transform(X)\n",
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\pipeline.py:605: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  res = transformer.transform(X)\n",
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\pipeline.py:605: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  res = transformer.transform(X)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.937455810525603"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline Training and testing\n",
    "# logreg = baseline_pipe.fit(pd.DataFrame(X_train_rus, columns = X_train.columns), y_train_rus)\n",
    "# y_score = logreg.predict_proba(pd.DataFrame(X_train_rus, columns = X_train.columns))\n",
    "# baseline= roc_auc_score(y_train_rus, y_score[:, 1])\n",
    "\n",
    "baseline = cross_val_score(logreg, pd.DataFrame(X_train_rus, columns = X_train.columns), y_train_rus, scoring='roc_auc', cv=5)\n",
    "baseline_cv_score = np.mean(baseline)\n",
    "baseline_cv_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying Target Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Form_of_Payment_or_Transfer_of_Value 6\n",
      "Dispute_Status_for_Publication 2\n",
      "Delay_in_Publication_Indicator 1\n",
      "Related_Product_Indicator 2\n",
      "Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Country 32\n",
      "Change_Type 3\n",
      "Submitting_Applicable_Manufacturer_or_Applicable_GPO_Name 1180\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Submitting_Applicable_Manufacturer_or_Applicable_GPO_Name']"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify which variables to target encode\n",
    "target_based_encoding = []\n",
    "for col in objVars:\n",
    "    print(col, len(X_train[col].unique()))\n",
    "    \n",
    "    if len(X_train[col].unique()) > 100:\n",
    "        target_based_encoding.append(col)\n",
    "\n",
    "target_based_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining continuous and categorical variables\n",
    "objVars = ['Form_of_Payment_or_Transfer_of_Value',\n",
    "           'Dispute_Status_for_Publication', \n",
    "           'Delay_in_Publication_Indicator',\n",
    "           'Related_Product_Indicator',\n",
    "           'Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Country',\n",
    "           'Change_Type']\n",
    "\n",
    "contVars = ['Total_Amount_of_Payment_USDollars']\n",
    "\n",
    "# contVars_ct = ColumnTransformer([(\"scalar\", StandardScaler(), contVars)])\n",
    "\n",
    "# catVars_ct = ColumnTransformer([(\"dummies\", OneHotEncoder(handle_unknown='ignore'), objVars)])\n",
    "\n",
    "# baseline_pipe = Pipeline([\n",
    "#                         (\"contvars\", contVars_ct),\n",
    "#                         (\"catvars\", catVars_ct),\n",
    "#                         (\"logreg\", LogisticRegression(solver='lbfgs', max_iter=1000))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining ColumnTransformer\n",
    "preprocessor = ColumnTransformer(transformers=[(\"scalar\", StandardScaler(), contVars),\n",
    "                                              (\"dummies\", OneHotEncoder(handle_unknown='ignore'), objVars),\n",
    "                                              (\"target_encoder\", TargetEncoder(clf_type=\"binary_clf\"), target_based_encoding)\n",
    "                                             ])\n",
    "\n",
    "# Create pipeplines\n",
    "baseline_pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                (\"logreg\", LogisticRegression(solver='lbfgs', max_iter=1000))\n",
    "                               ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\pipeline.py:605: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  res = transformer.transform(X)\n",
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\pipeline.py:605: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  res = transformer.transform(X)\n",
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\pipeline.py:605: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  res = transformer.transform(X)\n",
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\pipeline.py:605: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  res = transformer.transform(X)\n",
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\pipeline.py:605: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  res = transformer.transform(X)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.939610166041333"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline Training and testing\n",
    "baseline = cross_val_score(logreg, pd.DataFrame(X_train_rus, columns = X_train.columns), y_train_rus, scoring='roc_auc', cv=5)\n",
    "baseline_cv_score = np.mean(baseline)\n",
    "baseline_cv_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering ~ Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputing NA with 'Missing' values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_engineered = df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test split\n",
    "target = df_engineered['Target']\n",
    "features = df_engineered.drop(columns='Target')\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target)\n",
    "\n",
    "# Random undersampling\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_rus, y_train_rus = rus.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_vars = X_train.drop(columns=['Total_Amount_of_Payment_USDollars']).columns.values\n",
    "cont_vars = ['Total_Amount_of_Payment_USDollars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indicate_Drug_or_Biological_or_Device_or_Medical_Supply_4 5\n",
      "Indicate_Drug_or_Biological_or_Device_or_Medical_Supply_2 5\n",
      "Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Country 34\n",
      "Indicate_Drug_or_Biological_or_Device_or_Medical_Supply_1 5\n",
      "Form_of_Payment_or_Transfer_of_Value 6\n",
      "Physician_License_State_code5 34\n",
      "Indicate_Drug_or_Biological_or_Device_or_Medical_Supply_3 5\n",
      "Covered_or_Noncovered_Indicator_5 3\n",
      "Associated_Drug_or_Biological_NDC_1 1224\n",
      "Change_Type 3\n",
      "Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_State 47\n",
      "Name_of_Drug_or_Biological_or_Device_or_Medical_Supply_3 1769\n",
      "Product_Category_or_Therapeutic_Area_5 193\n",
      "Product_Category_or_Therapeutic_Area_4 298\n",
      "Submitting_Applicable_Manufacturer_or_Applicable_GPO_Name 1187\n",
      "Physician_License_State_code2 55\n",
      "Name_of_Drug_or_Biological_or_Device_or_Medical_Supply_1 8236\n",
      "Delay_in_Publication_Indicator 1\n",
      "Dispute_Status_for_Publication 2\n",
      "Physician_License_State_code3 49\n",
      "Name_of_Drug_or_Biological_or_Device_or_Medical_Supply_5 538\n",
      "Associated_Drug_or_Biological_NDC_2 531\n",
      "Physician_License_State_code1 59\n",
      "Associated_Drug_or_Biological_NDC_3 369\n",
      "Product_Category_or_Therapeutic_Area_1 1600\n",
      "Covered_or_Noncovered_Indicator_1 3\n",
      "Related_Product_Indicator 2\n",
      "Covered_or_Noncovered_Indicator_4 3\n",
      "Associated_Drug_or_Biological_NDC_4 196\n",
      "Physician_Specialty 377\n",
      "Associated_Drug_or_Biological_NDC_5 87\n",
      "Recipient_Primary_Business_Street_Address_Line1 299585\n",
      "Recipient_Country 16\n",
      "Covered_or_Noncovered_Indicator_3 3\n",
      "Covered_or_Noncovered_Indicator_2 3\n",
      "Name_of_Drug_or_Biological_or_Device_or_Medical_Supply_4 1035\n",
      "Indicate_Drug_or_Biological_or_Device_or_Medical_Supply_5 5\n",
      "Name_of_Drug_or_Biological_or_Device_or_Medical_Supply_2 2547\n",
      "Product_Category_or_Therapeutic_Area_2 526\n",
      "Recipient_City 15158\n",
      "Recipient_State 61\n",
      "Physician_License_State_code4 41\n",
      "Product_Category_or_Therapeutic_Area_3 399\n",
      "Physician_Primary_Type 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Associated_Drug_or_Biological_NDC_1',\n",
       " 'Name_of_Drug_or_Biological_or_Device_or_Medical_Supply_3',\n",
       " 'Product_Category_or_Therapeutic_Area_5',\n",
       " 'Product_Category_or_Therapeutic_Area_4',\n",
       " 'Submitting_Applicable_Manufacturer_or_Applicable_GPO_Name',\n",
       " 'Name_of_Drug_or_Biological_or_Device_or_Medical_Supply_1',\n",
       " 'Name_of_Drug_or_Biological_or_Device_or_Medical_Supply_5',\n",
       " 'Associated_Drug_or_Biological_NDC_2',\n",
       " 'Associated_Drug_or_Biological_NDC_3',\n",
       " 'Product_Category_or_Therapeutic_Area_1',\n",
       " 'Associated_Drug_or_Biological_NDC_4',\n",
       " 'Physician_Specialty',\n",
       " 'Recipient_Primary_Business_Street_Address_Line1',\n",
       " 'Name_of_Drug_or_Biological_or_Device_or_Medical_Supply_4',\n",
       " 'Name_of_Drug_or_Biological_or_Device_or_Medical_Supply_2',\n",
       " 'Product_Category_or_Therapeutic_Area_2',\n",
       " 'Recipient_City',\n",
       " 'Product_Category_or_Therapeutic_Area_3']"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify which variables to target encode\n",
    "target_based_encoding = []\n",
    "for col in obj_vars:\n",
    "    print(col, len(X_train[col].unique()))\n",
    "    \n",
    "    if len(X_train[col].unique()) > 100:\n",
    "        target_based_encoding.append(col)\n",
    "\n",
    "target_based_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final categorical variables\n",
    "categorical = [cols for cols in obj_vars if cols not in target_based_encoding]\n",
    "len(categorical) + len(target_based_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining ColumnTransformer\n",
    "preprocessor = ColumnTransformer(transformers=[(\"scalar\", StandardScaler(), cont_vars),\n",
    "                                              (\"dummies\", make_pipeline(SimpleImputer(strategy='constant', fill_value=\"Missing\"),\n",
    "                                                                        OneHotEncoder(handle_unknown='ignore')), categorical),\n",
    "                                              (\"target_encoder\", make_pipeline(SimpleImputer(strategy='constant', fill_value=\"Missing\"),\n",
    "                                                                               TargetEncoder(clf_type=\"binary_clf\")), target_based_encoding)\n",
    "                                             ])\n",
    "\n",
    "# Create pipeplines\n",
    "take2_pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                (\"logreg\", LogisticRegression(solver='lbfgs', max_iter=500))\n",
    "                               ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\pipeline.py:605: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  res = transformer.transform(X)\n",
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\pipeline.py:605: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  res = transformer.transform(X)\n",
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\pipeline.py:605: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  res = transformer.transform(X)\n",
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\pipeline.py:605: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  res = transformer.transform(X)\n",
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\Akshat\\Miniconda3\\envs\\aml_spring_19\\lib\\site-packages\\sklearn\\pipeline.py:605: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  res = transformer.transform(X)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9381459246035337"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline Training and testing\n",
    "baseline = cross_val_score(logreg, pd.DataFrame(X_train_rus, columns = X_train.columns), y_train_rus, scoring='roc_auc', cv=5)\n",
    "baseline_cv_score = np.mean(baseline)\n",
    "baseline_cv_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score = logreg.fit(pd.DataFrame(X_train_rus, columns = X_train.columns), \n",
    "                     pd.DataFrame(y_train_rus)).predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = logreg.predict(X_test)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_test, preds).ravel()\n",
    "print([tn, fp])\n",
    "print([fn, tp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "roc_auc_score(y_test, y_score[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_roc(y_test, list(y_score[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "average_precision_score(y_test, y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(y_test, y_score):\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_score)\n",
    "    \n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    lw = 2\n",
    "    plt.plot(fpr, tpr, color='darkorange',\n",
    "             lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = logreg.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
